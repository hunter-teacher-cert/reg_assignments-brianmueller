# Grading Schema

## Directions
* Look at the python lab files [here](https://github.com/hunter-teacher-cert/spring-2021-methods-2/tree/main/resources)
* Pick a lab, and create a grading schema for it. Assume you can assign any kind of grade you want.

## Lab: Rot13 [Lab](https://github.com/hunter-teacher-cert/spring-2021-methods-2/blob/main/resources/rot13_lab.py) | [Solution](https://github.com/hunter-teacher-cert/spring-2021-methods-2/blob/main/resources/rot13_lab_solved.py)

Problem 0: `encode_table()`

Problem 1: rot13 explanation/observation

Problem 2: `rot13char(c)`

Problem 3: `rot13table()`

Problem 4: `rot13(s)`

Problem 5: `rot13char_anycase(c)`

Problem 5 follow-up question re: `rot13(rot13(s))`

Problem 6: `rot13_full(s)`

## Grading

* 60% mastery of problems Problems 0, 2, 3, 4, 5, 6
  * 60%: all problems are correct
  * 40%: minor issues
  * 20%: major issues
  * 0%: no attempt
* 20% explanation of Problems 0, 2, 3, 4, 5, 6
  * 20%: code is thoroughly commented
  * 15%: minor issues
  * 10%: major issues
  * 0%: no attempt
* 20% reflection of Problems 1 and 5-follow-up
  * 20%: response is thoughtful and thorough
  * 15%: minor issues
  * 10%: major issues
  * 0%: no attempt

## Rationale
The bulk of the grade should reflect mastery of the programming content. But Explanation/Reflection have an equal share of the remaining grade that, if ignored, leaves a gap in the students' programming process (and thus the grade). 

* Minor issues would be things such as syntax/clerical errors, wrong vocabulary words, etc. 
* Major issues would be things such as conceptual errors.
